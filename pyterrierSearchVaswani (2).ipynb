{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78a794d-091d-45f1-b453-2a756d62f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "vaswani documents:   0%|                                                                                                                      | 0/11429 [00:00<?, ?it/s]\u001b[A\n",
      "vaswani documents:   0%|                                                                                                              | 1/11429 [00:00<36:02,  5.28it/s]\u001b[A\n",
      "vaswani documents:   3%|███▏                                                                                                      | 345/11429 [00:00<00:07, 1418.80it/s]\u001b[A\n",
      "vaswani documents:   5%|████▉                                                                                                     | 529/11429 [00:00<00:08, 1323.48it/s]\u001b[A\n",
      "vaswani documents:   6%|██████▎                                                                                                   | 685/11429 [00:00<00:07, 1388.42it/s]\u001b[A\n",
      "vaswani documents:   7%|███████▊                                                                                                  | 840/11429 [00:00<00:07, 1336.84it/s]\u001b[A\n",
      "vaswani documents:   9%|█████████▏                                                                                                | 984/11429 [00:00<00:08, 1192.49it/s]\u001b[A\n",
      "vaswani documents:  10%|██████████▏                                                                                              | 1112/11429 [00:00<00:09, 1053.70it/s]\u001b[A\n",
      "vaswani documents:  11%|███████████▎                                                                                             | 1225/11429 [00:01<00:10, 1003.74it/s]\u001b[A\n",
      "vaswani documents:  12%|████████████▎                                                                                             | 1330/11429 [00:01<00:16, 623.23it/s]\u001b[A\n",
      "vaswani documents:  12%|█████████████                                                                                             | 1412/11429 [00:01<00:15, 653.66it/s]\u001b[A\n",
      "vaswani documents:  13%|█████████████▊                                                                                            | 1493/11429 [00:01<00:17, 552.96it/s]\u001b[A\n",
      "vaswani documents:  14%|██████████████▌                                                                                           | 1564/11429 [00:01<00:17, 578.09it/s]\u001b[A\n",
      "vaswani documents:  14%|███████████████▏                                                                                          | 1632/11429 [00:02<00:17, 545.14it/s]\u001b[A\n",
      "vaswani documents:  15%|███████████████▊                                                                                          | 1710/11429 [00:02<00:17, 564.25it/s]\u001b[A\n",
      "vaswani documents:  16%|█████████████████▍                                                                                        | 1874/11429 [00:02<00:12, 783.51it/s]\u001b[A\n",
      "vaswani documents:  19%|███████████████████▋                                                                                     | 2138/11429 [00:02<00:07, 1225.76it/s]\u001b[A\n",
      "vaswani documents:  21%|█████████████████████▊                                                                                   | 2381/11429 [00:02<00:06, 1479.76it/s]\u001b[A\n",
      "vaswani documents:  22%|███████████████████████▌                                                                                 | 2568/11429 [00:02<00:05, 1571.14it/s]\u001b[A\n",
      "vaswani documents:  24%|█████████████████████████▏                                                                               | 2737/11429 [00:02<00:06, 1394.25it/s]\u001b[A\n",
      "vaswani documents:  26%|██████████████████████████▊                                                                              | 2920/11429 [00:02<00:05, 1492.14it/s]\u001b[A\n",
      "vaswani documents:  28%|█████████████████████████████▏                                                                           | 3174/11429 [00:02<00:04, 1745.87it/s]\u001b[A\n",
      "vaswani documents:  29%|██████████████████████████████▊                                                                          | 3358/11429 [00:03<00:06, 1235.26it/s]\u001b[A\n",
      "vaswani documents:  31%|████████████████████████████████▏                                                                        | 3508/11429 [00:03<00:06, 1209.50it/s]\u001b[A\n",
      "vaswani documents:  32%|█████████████████████████████████▊                                                                       | 3686/11429 [00:03<00:05, 1335.46it/s]\u001b[A\n",
      "vaswani documents:  34%|███████████████████████████████████▎                                                                     | 3837/11429 [00:03<00:07, 1002.27it/s]\u001b[A\n",
      "vaswani documents:  42%|███████████████████████████████████████████▉                                                             | 4789/11429 [00:03<00:02, 2697.88it/s]\u001b[A\n",
      "vaswani documents:  50%|████████████████████████████████████████████████████▉                                                    | 5761/11429 [00:03<00:01, 4247.69it/s]\u001b[A\n",
      "vaswani documents:  56%|███████████████████████████████████████████████████████████▏                                             | 6439/11429 [00:04<00:01, 4850.72it/s]\u001b[A\n",
      "vaswani documents:  64%|███████████████████████████████████████████████████████████████████▍                                     | 7337/11429 [00:04<00:00, 5888.18it/s]\u001b[A\n",
      "vaswani documents:  73%|█████████████████████████████████████████████████████████████████████████████                            | 8394/11429 [00:04<00:00, 7124.95it/s]\u001b[A\n",
      "vaswani documents:  84%|████████████████████████████████████████████████████████████████████████████████████████▎                | 9611/11429 [00:04<00:00, 8135.20it/s]\u001b[A\n",
      "vaswani documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 11429/11429 [00:04<00:00, 2554.05it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as gensim_downloader\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert import Searcher\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "import ir_datasets\n",
    "import pyterrier as pt\n",
    "from pyterrier.measures import *\n",
    "\n",
    "index_path = './vaswaniindex/'\n",
    "\n",
    "dataset =  pt.get_dataset(\"irds:vaswani\")\n",
    "index = pt.index.IterDictIndexer(\n",
    "    index_path,\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ").index(dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab0339e-2235-4fc2-b961-d3949ef3ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word2vec_model = gensim_downloader.load(\"glove-wiki-gigaword-100\")\n",
    "vectorizer = joblib.load('trained/vectorizervaswani.pkl')\n",
    "file = open(\"trained/doc_vecsvaswani.pickle\",'rb') \n",
    "doc_vecs = pickle.load(file)\n",
    "data_dir = './project-root/vaswani/raw/'\n",
    "collection = pd.read_csv(data_dir + \"collection.tsv\", sep='\\t', \n",
    "                                names=['doc_id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ba58ea-fa41-4b4e-8ebc-9ee3a08bc385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1347/3173451093.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) autoclass. (use pt.java.autoclass(...) instead) -- Deprecated since version 0.11.0.\n",
      "  tokenizer = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n"
     ]
    }
   ],
   "source": [
    "if not pt.java.started():\n",
    "    pt.init()\n",
    "\n",
    "tokenizer = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "def strip_markup(text):\n",
    "    return \" \".join(tokenizer.getTokens(text))\n",
    "\n",
    "def _preprocess_text(text: str) -> list:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "\n",
    "def stop_lemma(text: str) -> list:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return ' '.join([lemmatizer.lemmatize(token) for token in tokens if token not in stop_words])\n",
    "\n",
    "def stop_porter(text: str) -> list:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return ' '.join([stemmer.stem(token) for token in tokens if token not in stop_words])\n",
    "    \n",
    "def stop_word(text: str) -> list:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return ' '.join([token for token in tokens if token not in stop_words])\n",
    "\n",
    "def expand_query_wordnet(query: str, num_expansions: int = 2) -> str:\n",
    "    tokens = _preprocess_text(query)\n",
    "    expanded_terms = set(tokens)\n",
    "    for token in tokens:\n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(token)[:2]:  # Limit to top 2 synsets\n",
    "            for lemma in syn.lemmas()[:num_expansions]:\n",
    "                synonym = lemma.name().lower()\n",
    "                if synonym != token and synonym not in synonyms:\n",
    "                    synonyms.add(synonym)\n",
    "            if len(synonyms) >= num_expansions:\n",
    "                break\n",
    "        expanded_terms.update(synonyms)\n",
    "    return ' '.join(expanded_terms)\n",
    "\n",
    "def expand_query_word2vec(query: str, num_expansions: int = 2, threshold: float = 0.7) -> str:\n",
    "    topn=3\n",
    "    words = query.split()\n",
    "    expanded_words = words.copy()\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = [w for w, _ in word2vec_model.most_similar(word, topn=topn) \n",
    "                            if w.lower() != word.lower()]\n",
    "            expanded_words.extend(similar_words)\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    return ' '.join(expanded_words)\n",
    "\n",
    "def expand_query_pseudo_relevance(doc_vecs, query: str, collection: pd.DataFrame, \n",
    "                                 vectorizer: TfidfVectorizer, top_k: int = 3, \n",
    "                                 num_expansions: int = 2) -> str:\n",
    "    try:\n",
    "        query_vec = vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, doc_vecs)[0]\n",
    "        top_k_indices = np.argsort(similarities)[-top_k:]\n",
    "        top_k_docs = collection.iloc[top_k_indices]\n",
    "        top_k_vecs = vectorizer.transform(top_k_docs['text']).toarray()\n",
    "        mean_top_k = np.mean(top_k_vecs, axis=0)\n",
    "        original_vec = query_vec.toarray()[0]\n",
    "        combined_vec = 0.7 * mean_top_k + 0.3 * original_vec  # Rocchio-like weighting\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        top_indices = np.argsort(combined_vec)[-num_expansions:]\n",
    "        expansion_terms = [feature_names[idx] for idx in top_indices \n",
    "                          if feature_names[idx] not in query.lower().split()]\n",
    "    except IndexError:\n",
    "        print(len(collection))\n",
    "        print(collection)\n",
    "        print(vectorizer)\n",
    "        print(query)\n",
    "        print(doc_vecs)\n",
    "        print(query_vec)\n",
    "        print(top_k_indices)\n",
    "    return query + ' ' + ' '.join(expansion_terms)\n",
    "\n",
    "def expand_porter_stemmer(text: str) -> str:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return ' '.join([stemmer.stem(token) for token in tokens])\n",
    "    \n",
    "def comb(text: str, doc_vecs, collection, vectorizer) -> str:\n",
    "    q = expand_query_wordnet(text)\n",
    "    q = expand_query_word2vec(q)\n",
    "    q = expand_query_pseudo_relevance(doc_vecs, q, collection, vectorizer)\n",
    "    return expand_porter_stemmer(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87878697-3a8f-4483-9ca1-66c79e53778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP</th>\n",
       "      <th>RR</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP +</th>\n",
       "      <th>AP -</th>\n",
       "      <th>AP p-value</th>\n",
       "      <th>RR +</th>\n",
       "      <th>RR -</th>\n",
       "      <th>RR p-value</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.296517</td>\n",
       "      <td>0.725665</td>\n",
       "      <td>0.446609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stop</td>\n",
       "      <td>0.296986</td>\n",
       "      <td>0.727457</td>\n",
       "      <td>0.447187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.199335e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.199335e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.199335e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stop-Porter</td>\n",
       "      <td>0.277030</td>\n",
       "      <td>0.686217</td>\n",
       "      <td>0.423711</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.626489e-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.370605e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.863622e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop-Lemma</td>\n",
       "      <td>0.294246</td>\n",
       "      <td>0.721999</td>\n",
       "      <td>0.442597</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.183245e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.562424e-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.046201e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming</td>\n",
       "      <td>0.276865</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.422176</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.567204e-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.231831e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.180577e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wordnet</td>\n",
       "      <td>0.203801</td>\n",
       "      <td>0.543942</td>\n",
       "      <td>0.321790</td>\n",
       "      <td>18.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.070873e-10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.913180e-06</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.001826e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>0.553907</td>\n",
       "      <td>0.305802</td>\n",
       "      <td>8.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.391050e-13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.081216e-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.818189e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pseudo-relevance</td>\n",
       "      <td>0.285681</td>\n",
       "      <td>0.707794</td>\n",
       "      <td>0.437438</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>6.206860e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.836703e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.538543e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Combined</td>\n",
       "      <td>0.162655</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>0.266303</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.597736e-11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.775704e-08</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.523550e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name        AP        RR   nDCG@10  AP +  AP -    AP p-value  \\\n",
       "0              None  0.296517  0.725665  0.446609   NaN   NaN           NaN   \n",
       "1              Stop  0.296986  0.727457  0.447187   1.0   0.0  3.199335e-01   \n",
       "2       Stop-Porter  0.277030  0.686217  0.423711   6.0  28.0  1.626489e-02   \n",
       "3        Stop-Lemma  0.294246  0.721999  0.442597   3.0   4.0  4.183245e-01   \n",
       "4          Stemming  0.276865  0.685659  0.422176   6.0  29.0  1.567204e-02   \n",
       "5           Wordnet  0.203801  0.543942  0.321790  18.0  73.0  4.070873e-10   \n",
       "6          Word2Vec  0.186555  0.553907  0.305802   8.0  84.0  6.391050e-13   \n",
       "7  Pseudo-relevance  0.285681  0.707794  0.437438   7.0  82.0  6.206860e-04   \n",
       "8          Combined  0.162655  0.479302  0.266303  12.0  80.0  1.597736e-11   \n",
       "\n",
       "   RR +  RR -    RR p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value  \n",
       "0   NaN   NaN           NaN        NaN        NaN              NaN  \n",
       "1   1.0   0.0  3.199335e-01        1.0        0.0     3.199335e-01  \n",
       "2   3.0   9.0  2.370605e-02        5.0       17.0     3.863622e-02  \n",
       "3   2.0   2.0  5.562424e-01        3.0        4.0     4.046201e-01  \n",
       "4   3.0   9.0  2.231831e-02        5.0       17.0     3.180577e-02  \n",
       "5  12.0  41.0  4.913180e-06       14.0       64.0     5.001826e-08  \n",
       "6  10.0  42.0  1.081216e-05       17.0       66.0     2.818189e-09  \n",
       "7   1.0  13.0  5.836703e-02        5.0       20.0     7.538543e-02  \n",
       "8   9.0  48.0  2.775704e-08       15.0       69.0     2.523550e-09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "no_qe = pt.terrier.Retriever(index, wmodel=\"BM25\", metadata=[\"docno\", \"text\"], properties={\"termpipelines\": \"\"}, controls={\"qe\": \"off\"})\n",
    "qe_stop = pt.apply.query(lambda q: strip_markup(stop_word(q[\"query\"]))) >> no_qe\n",
    "qe_sp = pt.apply.query(lambda q: strip_markup(stop_porter(q[\"query\"]))) >> no_qe\n",
    "qe_sl = pt.apply.query(lambda q: strip_markup(stop_lemma(q[\"query\"]))) >> no_qe\n",
    "qe_wordnet = pt.apply.query(lambda q: strip_markup(expand_query_wordnet(q[\"query\"]))) >> no_qe\n",
    "qe_word2vec = pt.apply.query(lambda q: strip_markup(expand_query_word2vec(q[\"query\"]))) >> no_qe\n",
    "qe_pseudo = pt.apply.query(lambda q: strip_markup(expand_query_pseudo_relevance(doc_vecs, q[\"query\"], collection, vectorizer))) >> no_qe\n",
    "qe_stem = pt.apply.query(lambda q: strip_markup(expand_porter_stemmer(q[\"query\"]))) >> no_qe\n",
    "qe_comb = pt.apply.query(lambda q: strip_markup(comb(q[\"query\"], doc_vecs, collection, vectorizer))) >> no_qe\n",
    "pt.Experiment(\n",
    "    [no_qe, qe_stop, qe_sp, qe_sl, qe_stem, qe_wordnet, qe_word2vec, qe_pseudo, qe_comb],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[pt.measures.MAP(rel=1), RR(rel=1), nDCG@10],\n",
    "    baseline = 0,\n",
    "    names = ['None', 'Stop', 'Stop-Porter', 'Stop-Lemma', 'Stemming', 'Wordnet', 'Word2Vec', 'Pseudo-relevance', 'Combined']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d14b2a-4b02-42e1-8773-16fe362f198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 08, 15:05:33] #> Loading codec...\n",
      "[Apr 08, 15:05:33] #> Loading IVF...\n",
      "[Apr 08, 15:05:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1508.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 08, 15:05:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 48.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . measurement of dielectric constant of liquids by the use of microwave techniques, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10903,  1997,  3280,  2571, 22601,  5377,  1997, 26820,\n",
      "         2011,  1996,  2224,  1997, 18302,  5461,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP</th>\n",
       "      <th>RR</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP +</th>\n",
       "      <th>AP -</th>\n",
       "      <th>AP p-value</th>\n",
       "      <th>RR +</th>\n",
       "      <th>RR -</th>\n",
       "      <th>RR p-value</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.287854</td>\n",
       "      <td>0.747713</td>\n",
       "      <td>0.481308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stop</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.747092</td>\n",
       "      <td>0.465798</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.426888e-01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.693507e-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.252273e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stop-Porter</td>\n",
       "      <td>0.152022</td>\n",
       "      <td>0.490303</td>\n",
       "      <td>0.280053</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.270297e-13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.106572e-08</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9.466255e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop-Lemma</td>\n",
       "      <td>0.269861</td>\n",
       "      <td>0.751633</td>\n",
       "      <td>0.443310</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.784855e-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.553236e-01</td>\n",
       "      <td>27.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.901051e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming</td>\n",
       "      <td>0.162226</td>\n",
       "      <td>0.529872</td>\n",
       "      <td>0.299730</td>\n",
       "      <td>14.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.280454e-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.924347e-07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.124664e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wordnet</td>\n",
       "      <td>0.164237</td>\n",
       "      <td>0.541097</td>\n",
       "      <td>0.289337</td>\n",
       "      <td>9.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.839297e-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>9.570426e-07</td>\n",
       "      <td>13.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.745998e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.183070</td>\n",
       "      <td>0.561631</td>\n",
       "      <td>0.334193</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.131425e-11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.516649e-06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.626242e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pseudo-relevance</td>\n",
       "      <td>0.274182</td>\n",
       "      <td>0.717897</td>\n",
       "      <td>0.455576</td>\n",
       "      <td>35.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.624291e-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.290940e-01</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.217400e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Combined</td>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.362666</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>7.883576e-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.562260e-13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.439623e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name        AP        RR   nDCG@10  AP +  AP -    AP p-value  \\\n",
       "0              None  0.287854  0.747713  0.481308   NaN   NaN           NaN   \n",
       "1              Stop  0.283280  0.747092  0.465798  44.0  38.0  4.426888e-01   \n",
       "2       Stop-Porter  0.152022  0.490303  0.280053  16.0  76.0  2.270297e-13   \n",
       "3        Stop-Lemma  0.269861  0.751633  0.443310  38.0  52.0  1.784855e-02   \n",
       "4          Stemming  0.162226  0.529872  0.299730  14.0  78.0  1.280454e-13   \n",
       "5           Wordnet  0.164237  0.541097  0.289337   9.0  83.0  1.839297e-13   \n",
       "6          Word2Vec  0.183070  0.561631  0.334193  13.0  79.0  6.131425e-11   \n",
       "7  Pseudo-relevance  0.274182  0.717897  0.455576  35.0  57.0  1.624291e-02   \n",
       "8          Combined  0.079989  0.362666  0.176048   3.0  89.0  7.883576e-22   \n",
       "\n",
       "   RR +  RR -    RR p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value  \n",
       "0   NaN   NaN           NaN        NaN        NaN              NaN  \n",
       "1  11.0  12.0  9.693507e-01       32.0       41.0     7.252273e-02  \n",
       "2  12.0  46.0  1.106572e-08       18.0       69.0     9.466255e-13  \n",
       "3  12.0  12.0  8.553236e-01       27.0       55.0     4.901051e-04  \n",
       "4   8.0  41.0  1.924347e-07       16.0       70.0     6.124664e-12  \n",
       "5   8.0  46.0  9.570426e-07       13.0       72.0     1.745998e-14  \n",
       "6   7.0  49.0  3.516649e-06       16.0       67.0     1.626242e-09  \n",
       "7  12.0  18.0  1.290940e-01       28.0       52.0     8.217400e-03  \n",
       "8   5.0  66.0  1.562260e-13        7.0       80.0     5.439623e-20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert import Searcher\n",
    "from colbert.data import Collection\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "from pyterrier.measures import *\n",
    "if not pt.java.started():\n",
    "  pt.init()\n",
    "data_dir = './project-root/vaswani/raw/collection.tsv'\n",
    "collection_text = pd.read_csv(data_dir, sep=\"\\t\", names=['id', 'text'])\n",
    "# qrelstsv = pd.read_csv('./project-root/vaswani/raw/qrels.dev.tsv', sep=\"\\t\", names=['qid','iteration','docno','label'])\n",
    "# qrelstsv['qid'] = qrelstsv['qid'].astype(str)\n",
    "# qrelstsv['iteration'] = qrelstsv['iteration'].astype(str)\n",
    "# qrelstsv['docno'] = qrelstsv['docno'].astype(str)\n",
    "# qrelstsv['label'] = qrelstsv['label'].astype(int)\n",
    "collection2 = Collection(data=collection_text['text'].tolist())\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "if __name__=='__main__':\n",
    "    with Run().context(RunConfig(nranks=1, experiment=\"vaswaniindex\")):\n",
    "        config = ColBERTConfig(\n",
    "            root=\"experiments\",\n",
    "            collection=collection2\n",
    "        )\n",
    "        searcher = Searcher(index=\"vaswaniindex\", config=config)\n",
    "\n",
    "class MyColbert:\n",
    "    def __init__(self, searcher, method):\n",
    "        self.searcher = searcher \n",
    "        self.method = method\n",
    "    \n",
    "    def transform(self, df):\n",
    "        results = None\n",
    "        for index, row in df.iterrows():\n",
    "            query = row['query']\n",
    "            if self.method is not None:\n",
    "                query = self.method(query)\n",
    "            result = self.searcher.search(query, k=100)\n",
    "            result = pd.DataFrame(result).transpose()#, columns=['doc_index', 'rank', 'value'])\n",
    "            result.columns = ['docno', 'rank', 'score']\n",
    "            result['docno'] = result['docno'] + 1\n",
    "            result['docno'] = result['docno'].astype(int)\n",
    "            result['qid'] = row['qid']\n",
    "            if results is None:\n",
    "                results = result\n",
    "            else:\n",
    "                results = pd.concat([results, result])\n",
    "        return results\n",
    "        \n",
    "        \n",
    "no_qe = MyColbert(searcher, None)\n",
    "qe_stop = MyColbert(searcher, lambda x: stop_word(x))\n",
    "qe_sp = MyColbert(searcher, lambda x: stop_porter(x))\n",
    "qe_sl = MyColbert(searcher, lambda x: stop_lemma(x))\n",
    "qe_wordnet = MyColbert(searcher, lambda x: expand_query_wordnet(x))\n",
    "qe_word2vec = MyColbert(searcher, lambda x: expand_query_word2vec(x))\n",
    "qe_pseudo = MyColbert(searcher, lambda x: expand_query_pseudo_relevance(doc_vecs, x, collection_text, vectorizer))\n",
    "qe_stem = MyColbert(searcher, lambda x: expand_porter_stemmer(x))\n",
    "qe_comb = MyColbert(searcher, lambda x: comb(x, doc_vecs, collection_text, vectorizer))\n",
    "\n",
    "pt.Experiment(\n",
    "    [no_qe, qe_stop, qe_sp, qe_sl, qe_stem, qe_wordnet, qe_word2vec, qe_pseudo, qe_comb],\n",
    "    # [no_qe],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[pt.measures.MAP(rel=1), RR(rel=1), nDCG@10],\n",
    "    baseline = 0,\n",
    "    names = ['None', 'Stop', 'Stop-Porter', 'Stop-Lemma', 'Stemming', 'Wordnet', 'Word2Vec', 'Pseudo-relevance', 'Combined']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb9d98-2554-4b9d-8cb3-d77d2077a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from pyterrier.measures import *\n",
    "from pyterrier_t5 import MonoT5ReRanker, DuoT5ReRanker\n",
    "monoT5 = MonoT5ReRanker() \n",
    "duoT5 = DuoT5ReRanker() \n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", properties={\"termpipelines\": \"\"}, controls={\"qe\": \"off\"})\n",
    "mono_pipeline = (bm25 % 50) >> pt.text.get_text(dataset, \"text\") >> monoT5\n",
    "duo_pipeline = mono_pipeline % 5 >> duoT5\n",
    "\n",
    "no_qe = duo_pipeline\n",
    "qe_stop = pt.apply.query(lambda q: strip_markup(stop_word(q[\"query\"]))) >> no_qe\n",
    "qe_sp = pt.apply.query(lambda q: strip_markup(stop_porter(q[\"query\"]))) >> no_qe\n",
    "qe_sl = pt.apply.query(lambda q: strip_markup(stop_lemma(q[\"query\"]))) >> no_qe\n",
    "qe_stem = pt.apply.query(lambda q: strip_markup(expand_porter_stemmer(q[\"query\"]))) >> no_qe\n",
    "qe_wordnet = pt.apply.query(lambda q: strip_markup(expand_query_wordnet(q[\"query\"]))) >> no_qe\n",
    "qe_word2vec = pt.apply.query(lambda q: strip_markup(expand_query_word2vec(q[\"query\"]))) >> no_qe\n",
    "qe_pseudo = pt.apply.query(lambda q: strip_markup(expand_query_pseudo_relevance(doc_vecs, q[\"query\"], collection, vectorizer))) >> no_qe\n",
    "qe_comb = pt.apply.query(lambda q: strip_markup(comb(q[\"query\"], doc_vecs, collection, vectorizer))) >> no_qe\n",
    "\n",
    "\n",
    "pt.Experiment(\n",
    "    [no_qe, qe_stop, qe_sp, qe_sl, qe_stem, qe_wordnet, qe_word2vec, qe_pseudo, qe_comb],\n",
    "    dataset.get_topics()[:50],\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[pt.measures.MAP(rel=1), RR(rel=1), nDCG@10],\n",
    "    baseline = 0,\n",
    "    names = ['None', 'Stop', 'Stop-Porter', 'Stop-Lemma', 'Stemming', 'Wordnet', 'Word2Vec', 'Pseudo-relevance', 'Combined']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f37efbb-364c-4051-900a-fe4ae7a24549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:57:20.618 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of ''. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP</th>\n",
       "      <th>RR</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP +</th>\n",
       "      <th>AP -</th>\n",
       "      <th>AP p-value</th>\n",
       "      <th>RR +</th>\n",
       "      <th>RR -</th>\n",
       "      <th>RR p-value</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.063776</td>\n",
       "      <td>0.337277</td>\n",
       "      <td>0.139544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stop</td>\n",
       "      <td>0.064467</td>\n",
       "      <td>0.363313</td>\n",
       "      <td>0.144371</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.570021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.238625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.248295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stop-Porter</td>\n",
       "      <td>0.139352</td>\n",
       "      <td>0.253369</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.337981</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.974255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop-Lemma</td>\n",
       "      <td>0.100920</td>\n",
       "      <td>0.350505</td>\n",
       "      <td>0.171458</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.114308</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.714737</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.309293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.174221</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.982675</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.479805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wordnet</td>\n",
       "      <td>0.092496</td>\n",
       "      <td>0.359553</td>\n",
       "      <td>0.130274</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.312095</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.835844</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.860879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.158027</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.162927</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.010706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pseudo-relevance</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.233699</td>\n",
       "      <td>0.096809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.027252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Combined</td>\n",
       "      <td>0.059476</td>\n",
       "      <td>0.217967</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.831395</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.342630</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.290636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name        AP        RR   nDCG@10  AP +  AP -  AP p-value  \\\n",
       "0              None  0.063776  0.337277  0.139544   NaN   NaN         NaN   \n",
       "1              Stop  0.064467  0.363313  0.144371   5.0   2.0    0.570021   \n",
       "2       Stop-Porter  0.139352  0.253369  0.141009  15.0   4.0    0.008896   \n",
       "3        Stop-Lemma  0.100920  0.350505  0.171458  13.0   2.0    0.114308   \n",
       "4          Stemming  0.149641  0.335027  0.174221  16.0   3.0    0.005234   \n",
       "5           Wordnet  0.092496  0.359553  0.130274   9.0  10.0    0.312095   \n",
       "6          Word2Vec  0.048062  0.158027  0.054901   7.0  12.0    0.162927   \n",
       "7  Pseudo-relevance  0.049534  0.233699  0.096809   1.0  16.0    0.005344   \n",
       "8          Combined  0.059476  0.217967  0.088333   9.0  10.0    0.831395   \n",
       "\n",
       "   RR +  RR -  RR p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value  \n",
       "0   NaN   NaN         NaN        NaN        NaN              NaN  \n",
       "1   4.0   2.0    0.238625        2.0        1.0         0.248295  \n",
       "2   8.0   8.0    0.337981        6.0        7.0         0.974255  \n",
       "3   8.0   4.0    0.714737        5.0        5.0         0.309293  \n",
       "4  11.0   6.0    0.982675       10.0        6.0         0.479805  \n",
       "5   6.0  10.0    0.835844        4.0        8.0         0.860879  \n",
       "6   5.0  12.0    0.022776        0.0       12.0         0.010706  \n",
       "7   0.0   9.0    0.094776        0.0        6.0         0.027252  \n",
       "8   7.0  12.0    0.342630        5.0        9.0         0.290636  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from pyterrier.measures import *\n",
    "\n",
    "\n",
    "params = {'objective': 'rank:ndcg',\n",
    "          'learning_rate': 0.1,\n",
    "          'gamma': 1.0, \n",
    "          'min_child_weight': 0.1,\n",
    "          'max_depth': 6,\n",
    "          'random_state': 42\n",
    "         }\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()\n",
    "train_topics, valid_topics, test_topics = np.split(topics, [int(.6*len(topics)), int(.8*len(topics))])\n",
    "\n",
    "fbr3f = pt.terrier.FeaturesRetriever(index, wmodel=\"BM25\", features=  ['WMODEL:TF_IDF', 'WMODEL:PL2', 'WMODEL:BM25', \n",
    "                                                 'WMODEL:DirichletLM', 'WMODEL:Hiemstra_LM', \n",
    "                                                 'WMODEL:DFR_BM25', 'WMODEL:InL2', 'WMODEL:LGD', \n",
    "                                                 'WMODEL:DLH', 'WMODEL:DPH', 'WMODEL:LemurTF_IDF'], properties={\"termpipelines\": \"\"}, controls={\"qe\": \"off\"})\n",
    "BaseLTR_LM = fbr3f >> pt.ltr.apply_learned_model(xgb.sklearn.XGBRanker(**params), form='ltr')\n",
    "BaseLTR_LM.fit(train_topics, qrels, valid_topics, qrels)\n",
    "\n",
    "no_qe = BaseLTR_LM\n",
    "qe_stop = pt.apply.query(lambda q: strip_markup(stop_word(q[\"query\"]))) >> no_qe\n",
    "qe_sp = pt.apply.query(lambda q: strip_markup(stop_porter(q[\"query\"]))) >> no_qe\n",
    "qe_sl = pt.apply.query(lambda q: strip_markup(stop_lemma(q[\"query\"]))) >> no_qe\n",
    "qe_stem = pt.apply.query(lambda q: strip_markup(expand_porter_stemmer(q[\"query\"]))) >> no_qe\n",
    "qe_wordnet = pt.apply.query(lambda q: strip_markup(expand_query_wordnet(q[\"query\"]))) >> no_qe\n",
    "qe_word2vec = pt.apply.query(lambda q: strip_markup(expand_query_word2vec(q[\"query\"]))) >> no_qe\n",
    "qe_pseudo = pt.apply.query(lambda q: strip_markup(expand_query_pseudo_relevance(doc_vecs, q[\"query\"], collection, vectorizer))) >> no_qe\n",
    "qe_comb = pt.apply.query(lambda q: strip_markup(comb(q[\"query\"], doc_vecs, collection, vectorizer))) >> no_qe\n",
    "\n",
    "\n",
    "pt.Experiment(\n",
    "    [no_qe, qe_stop, qe_sp, qe_sl, qe_stem, qe_wordnet, qe_word2vec, qe_pseudo, qe_comb],\n",
    "    # [bm25, BaseLTR_LM, lmart_l_pipe],\n",
    "    test_topics,\n",
    "    qrels,\n",
    "    eval_metrics=[pt.measures.MAP(rel=1), RR(rel=1), nDCG@10],\n",
    "    baseline = 0,\n",
    "    names = ['None', 'Stop', 'Stop-Porter', 'Stop-Lemma', 'Stemming', 'Wordnet', 'Word2Vec', 'Pseudo-relevance', 'Combined']\n",
    "    # names = ['bm25', 'xgb', 'lgbm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7491f-0983-414d-87fc-c187134b9668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
